{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/3983835478.py:4: DtypeWarning: Columns (7,13,19,21,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  rawWeatherDf = pd.read_csv(r'/Users/aaroncao/Documents/California Wildfire Project/3354623.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            STATION                    NAME   LATITUDE   LONGITUDE  ELEVATION  \\\n",
      "0       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "1       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "2       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "3       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "4       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "...             ...                     ...        ...         ...        ...   \n",
      "110536  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110537  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110538  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110539  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110540  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "\n",
      "              DATE  AWND AWND_ATTRIBUTES  DAPR DAPR_ATTRIBUTES  ...  WT08  \\\n",
      "0       2017-01-01   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "1       2017-01-02   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "2       2017-01-03   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "3       2017-01-04   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "4       2017-01-05   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "...            ...   ...             ...   ...             ...  ...   ...   \n",
      "110536  2018-11-11   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "110537  2018-11-12   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "110538  2018-11-13   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "110539  2018-11-14   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "110540  2018-11-15   NaN             NaN   NaN             NaN  ...   NaN   \n",
      "\n",
      "       WT08_ATTRIBUTES  WT10 WT10_ATTRIBUTES  WT11 WT11_ATTRIBUTES  WT13  \\\n",
      "0                  NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "1                  NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "2                  NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "3                  NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "4                  NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "...                ...   ...             ...   ...             ...   ...   \n",
      "110536             NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "110537             NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "110538             NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "110539             NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "110540             NaN   NaN             NaN   NaN             NaN   NaN   \n",
      "\n",
      "       WT13_ATTRIBUTES  WT16 WT16_ATTRIBUTES  \n",
      "0                  NaN   NaN             NaN  \n",
      "1                  NaN   NaN             NaN  \n",
      "2                  NaN   NaN             NaN  \n",
      "3                  NaN   NaN             NaN  \n",
      "4                  NaN   NaN             NaN  \n",
      "...                ...   ...             ...  \n",
      "110536             NaN   NaN             NaN  \n",
      "110537             NaN   NaN             NaN  \n",
      "110538             NaN   NaN             NaN  \n",
      "110539             NaN   NaN             NaN  \n",
      "110540             NaN   NaN             NaN  \n",
      "\n",
      "[110541 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "rawWeatherDf = pd.read_csv(r'/Users/aaroncao/Documents/California Wildfire Project/3354623.csv')\n",
    "print(rawWeatherDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calculate_distance(latitude1, longitude1, elevation1, latitude2, longitude2, elevation2): #meters\n",
    "    # Convert latitude and longitude to radians\n",
    "    lat1 = math.radians(latitude1)\n",
    "    lon1 = math.radians(longitude1)\n",
    "    lat2 = math.radians(latitude2)\n",
    "    lon2 = math.radians(longitude2)\n",
    "\n",
    "    # Earth's radius (approximate value for average radius in meters)\n",
    "    radius = 6371000  # meters\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "\n",
    "    # Calculate the horizontal distance\n",
    "    horizontal_distance = radius * c\n",
    "\n",
    "    # Calculate the elevation difference\n",
    "    vertical_distance = elevation2 - elevation1\n",
    "\n",
    "    # Calculate the overall 3D distance\n",
    "    distance = math.sqrt(horizontal_distance**2 + vertical_distance**2)\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION\n",
      "USW00093138    2557\n",
      "USC00042805    2557\n",
      "USC00044211    2557\n",
      "USW00053151    2557\n",
      "US1CARV0008    2557\n",
      "               ... \n",
      "US1CARV0064      36\n",
      "US1CARV0071      20\n",
      "US1CARV0006      13\n",
      "US1CARV0010       2\n",
      "US1CARV0078       1\n",
      "Length: 74, dtype: int64\n",
      "STATION\n",
      "USW00093138    2557\n",
      "USC00042805    2557\n",
      "USC00044211    2557\n",
      "USW00053151    2557\n",
      "US1CARV0008    2557\n",
      "               ... \n",
      "US1CARV0064      36\n",
      "US1CARV0071      20\n",
      "US1CARV0006      13\n",
      "US1CARV0010       2\n",
      "US1CARV0078       1\n",
      "Length: 74, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rawWeatherDf.value_counts('STATION'))\n",
    "groupedByStationDf = rawWeatherDf.groupby('STATION')\n",
    "#for group_name, df_group in groupedByStationDf:\n",
    "#    if len(df_group)<200:\n",
    "#    rawWeatherDf = rawWeatherDf[rawWeatherDf['STATION']!=group_name]\n",
    "print(rawWeatherDf.value_counts('STATION'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION                 0\n",
      "NAME                    0\n",
      "LATITUDE                0\n",
      "LONGITUDE               0\n",
      "ELEVATION               0\n",
      "                    ...  \n",
      "WT11_ATTRIBUTES    110440\n",
      "WT13               110539\n",
      "WT13_ATTRIBUTES    110539\n",
      "WT16               110533\n",
      "WT16_ATTRIBUTES    110533\n",
      "Length: 64, dtype: int64\n",
      "110541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nan_count = rawWeatherDf.isna().sum()\n",
    "print(nan_count)\n",
    "print(rawWeatherDf.shape[0])\n",
    "rawWeatherDf = rawWeatherDf[['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'DATE', 'AWND', 'PRCP', 'SNWD', 'TAVG', 'TMAX', 'TMIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            STATION                    NAME   LATITUDE   LONGITUDE  ELEVATION  \\\n",
      "0       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "1       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "2       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "3       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "4       USC00045091    LONG VALLEY 2, CA US  33.812990 -116.641930     2554.2   \n",
      "...             ...                     ...        ...         ...        ...   \n",
      "110536  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110537  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110538  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110539  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "110540  US1CARV0054  RIVERSIDE 0.0 W, CA US  33.940402 -117.398175      264.9   \n",
      "\n",
      "             DATE  AWND  PRCP  SNWD  TAVG  TMAX  TMIN  awndnan  prcpnan  \\\n",
      "0      2017-01-01   NaN   0.3   NaN   NaN  34.0  16.0        1        0   \n",
      "1      2017-01-02   NaN   0.0   NaN   NaN  40.0  30.0        1        0   \n",
      "2      2017-01-03   NaN   0.0   NaN   NaN  38.0  26.0        1        0   \n",
      "3      2017-01-04   NaN   0.0   NaN   NaN  40.0  18.0        1        0   \n",
      "4      2017-01-05   NaN   0.0   NaN   NaN  46.0  36.0        1        0   \n",
      "...           ...   ...   ...   ...   ...   ...   ...      ...      ...   \n",
      "110536 2018-11-11   NaN   0.0   NaN   NaN   NaN   NaN        1        0   \n",
      "110537 2018-11-12   NaN   0.0   NaN   NaN   NaN   NaN        1        0   \n",
      "110538 2018-11-13   NaN   0.0   NaN   NaN   NaN   NaN        1        0   \n",
      "110539 2018-11-14   NaN   0.0   NaN   NaN   NaN   NaN        1        0   \n",
      "110540 2018-11-15   NaN   0.0   NaN   NaN   NaN   NaN        1        0   \n",
      "\n",
      "        snwdnan  tavgnan  tmaxnan  tminnan  \n",
      "0             1        1        0        0  \n",
      "1             1        1        0        0  \n",
      "2             1        1        0        0  \n",
      "3             1        1        0        0  \n",
      "4             1        1        0        0  \n",
      "...         ...      ...      ...      ...  \n",
      "110536        1        1        1        1  \n",
      "110537        1        1        1        1  \n",
      "110538        1        1        1        1  \n",
      "110539        1        1        1        1  \n",
      "110540        1        1        1        1  \n",
      "\n",
      "[110541 rows x 18 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['DATE'] = pd.to_datetime(rawWeatherDf['DATE'], format='%Y-%m-%d')\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['awndnan'] = 0\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['prcpnan'] = 0\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['snwdnan'] = 0\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['tavgnan'] = 0\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['tmaxnan'] = 0\n",
      "/var/folders/3r/whhpn5fn6bx9pr68gv_sb7p80000gn/T/ipykernel_63282/58482309.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rawWeatherDf['tminnan'] = 0\n"
     ]
    }
   ],
   "source": [
    "rawWeatherDf['DATE'] = pd.to_datetime(rawWeatherDf['DATE'], format='%Y-%m-%d')\n",
    "rawWeatherDf['awndnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['AWND'].isnull(), 'awndnan'] = 1\n",
    "rawWeatherDf['prcpnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['PRCP'].isnull(), 'prcpnan'] = 1\n",
    "rawWeatherDf['snwdnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['SNWD'].isnull(), 'snwdnan'] = 1\n",
    "rawWeatherDf['tavgnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['TAVG'].isnull(), 'tavgnan'] = 1\n",
    "rawWeatherDf['tmaxnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['TMAX'].isnull(), 'tmaxnan'] = 1\n",
    "rawWeatherDf['tminnan'] = 0\n",
    "rawWeatherDf.loc[rawWeatherDf['TMIN'].isnull(), 'tminnan'] = 1\n",
    "print(rawWeatherDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         NAME   LATITUDE   LONGITUDE  \\\n",
      "STATION                                                                \n",
      "US1CARV0002           IDYLLWILD 1.8 NW, CA US  33.763056 -116.735000   \n",
      "US1CARV0003       THOUSAND PALMS 0.7 W, CA US  33.821200 -116.397800   \n",
      "US1CARV0004  DESERT HOT SPRINGS 3.0 NW, CA US  33.985460 -116.541467   \n",
      "US1CARV0005              HEMET 4.1 ENE, CA US  33.752700 -116.919600   \n",
      "US1CARV0006             CORONA 12.5 SE, CA US  33.734600 -117.431500   \n",
      "...                                       ...        ...         ...   \n",
      "USW00023119                  MARCH AFB, CA US  33.900000 -117.250000   \n",
      "USW00023158                BLYTHE ASOS, CA US  33.618760 -114.714510   \n",
      "USW00053151             FALLBROOK 5 NE, CA US  33.439200 -117.190400   \n",
      "USW00053175   CORONA MUNICIPAL AIRPORT, CA US  33.897650 -117.602430   \n",
      "USW00093138          PALM SPRINGS ASOS, CA US  33.822160 -116.504330   \n",
      "\n",
      "             ELEVATION                                        stationList  \n",
      "STATION                                                                    \n",
      "US1CARV0002     1927.9  [USR0000CCRT, USC00043855, USC00045091, USR000...  \n",
      "US1CARV0003       77.4  [USC00046635, US1CARV0020, US1CARV0033, US1CAR...  \n",
      "US1CARV0004      408.1  [USC00047123, USC00042598, USC00042410, USR000...  \n",
      "US1CARV0005      517.6  [USC00041738, USC00043855, US1CARV0058, USC000...  \n",
      "US1CARV0006      396.8  [US1CARV0072, US1CARV0033, USC00044259, USW000...  \n",
      "...                ...                                                ...  \n",
      "USW00023119      468.2  [US1CARV0021, USW00003104, US1CARV0017, USC000...  \n",
      "USW00023158      120.4  [USC00040924, USW00003104, USC00044259, USR000...  \n",
      "USW00053151      347.5  [USR0000CSRO, USR0000CLHO, USC00041738, USC000...  \n",
      "USW00053175      162.5  [USC00046635, USW00093138, US1CARV0066, US1CAR...  \n",
      "USW00093138      124.7  [US1CARV0028, USW00053175, US1CARV0031, US1CAR...  \n",
      "\n",
      "[74 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stationInfoDf = rawWeatherDf.groupby('STATION', as_index=True).nth(0)[['NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION']]\n",
    "#calculate_distance(latitude1, longitude1, elevation1, latitude2, longitude2, elevation2)\n",
    "\n",
    "for index, row in stationInfoDf.iterrows():\n",
    "    currStation = index\n",
    "    currLatitude = row['LATITUDE']\n",
    "    currLongitude = row['LONGITUDE']\n",
    "    currElevation = row['ELEVATION']\n",
    "    stationListWithDistances = []\n",
    "    for otherIndex, otherRow in stationInfoDf.iterrows(): #sick names lol\n",
    "        otherLat = otherRow['LATITUDE']\n",
    "        otherLon = otherRow['LONGITUDE']\n",
    "        otherEle = otherRow['ELEVATION']\n",
    "        distance = calculate_distance(currLatitude, currLongitude, currElevation, otherLat, otherLon, otherEle)\n",
    "        stationListWithDistances.append([otherIndex, distance])\n",
    "    stationListWithDistances = np.asarray(stationListWithDistances)\n",
    "    stationListWithDistances = stationListWithDistances[stationListWithDistances[:,1].argsort()]\n",
    "    stationList = stationListWithDistances[:,0]\n",
    "    stationList = np.delete(stationList, 0)\n",
    "    stationInfoDf.at[index, 'stationList'] = stationList\n",
    "print(stationInfoDf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            STATION       DATE  AWND  PRCP  SNWD  TAVG  TMAX  TMIN  awndnan  \\\n",
      "0       USC00045091 2017-01-01   NaN   0.3   NaN   NaN  34.0  16.0        1   \n",
      "1       USC00045091 2017-01-02   NaN   0.0   NaN   NaN  40.0  30.0        1   \n",
      "2       USC00045091 2017-01-03   NaN   0.0   NaN   NaN  38.0  26.0        1   \n",
      "3       USC00045091 2017-01-04   NaN   0.0   NaN   NaN  40.0  18.0        1   \n",
      "4       USC00045091 2017-01-05   NaN   0.0   NaN   NaN  46.0  36.0        1   \n",
      "...             ...        ...   ...   ...   ...   ...   ...   ...      ...   \n",
      "110536  US1CARV0054 2018-11-11   NaN   0.0   NaN   NaN   NaN   NaN        1   \n",
      "110537  US1CARV0054 2018-11-12   NaN   0.0   NaN   NaN   NaN   NaN        1   \n",
      "110538  US1CARV0054 2018-11-13   NaN   0.0   NaN   NaN   NaN   NaN        1   \n",
      "110539  US1CARV0054 2018-11-14   NaN   0.0   NaN   NaN   NaN   NaN        1   \n",
      "110540  US1CARV0054 2018-11-15   NaN   0.0   NaN   NaN   NaN   NaN        1   \n",
      "\n",
      "        prcpnan  snwdnan  tavgnan  tmaxnan  tminnan  \n",
      "0             0        1        1        0        0  \n",
      "1             0        1        1        0        0  \n",
      "2             0        1        1        0        0  \n",
      "3             0        1        1        0        0  \n",
      "4             0        1        1        0        0  \n",
      "...         ...      ...      ...      ...      ...  \n",
      "110536        0        1        1        1        1  \n",
      "110537        0        1        1        1        1  \n",
      "110538        0        1        1        1        1  \n",
      "110539        0        1        1        1        1  \n",
      "110540        0        1        1        1        1  \n",
      "\n",
      "[110541 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "weeklyWeatherDf = rawWeatherDf.copy()\n",
    "weeklyWeatherDf.drop(['NAME','LATITUDE','LONGITUDE','ELEVATION'], axis=1, inplace=True)\n",
    "print(weeklyWeatherDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DATE      STATION   AWND  PRCP  SNWD  TAVG   TMAX   TMIN  awndnan  \\\n",
      "0     2012-12-30  US1CARV0002   0.00  0.00  17.5   0.0    0.0    0.0        6   \n",
      "1     2013-01-06  US1CARV0002   0.00  0.38   1.5   0.0    0.0    0.0        7   \n",
      "2     2013-01-13  US1CARV0002   0.00  0.00   0.0   0.0    0.0    0.0        7   \n",
      "3     2013-01-20  US1CARV0002   0.00  2.23   0.0   0.0    0.0    0.0        7   \n",
      "4     2013-01-27  US1CARV0002   0.00  0.40   2.5   0.0    0.0    0.0        7   \n",
      "...          ...          ...    ...   ...   ...   ...    ...    ...      ...   \n",
      "18813 2019-12-01  USW00093138  20.35  0.42   0.0   0.0  470.0  362.0        0   \n",
      "18814 2019-12-08  USW00093138  28.41  0.00   0.0   0.0  509.0  346.0        0   \n",
      "18815 2019-12-15  USW00093138  35.57  0.00   0.0   0.0  463.0  309.0        0   \n",
      "18816 2019-12-22  USW00093138  23.27  0.96   0.0   0.0  427.0  308.0        0   \n",
      "18817 2019-12-29  USW00093138  17.45  0.00   0.0   0.0  197.0  139.0        0   \n",
      "\n",
      "       prcpnan  snwdnan  tavgnan  tmaxnan  tminnan  absTMAX  absTMIN  \n",
      "0            0        0        6        6        6      NaN      NaN  \n",
      "1            0        1        7        7        7      NaN      NaN  \n",
      "2            0        3        7        7        7      NaN      NaN  \n",
      "3            0        3        7        7        7      NaN      NaN  \n",
      "4            0        4        7        7        7      NaN      NaN  \n",
      "...        ...      ...      ...      ...      ...      ...      ...  \n",
      "18813        0        0        7        0        0     71.0     47.0  \n",
      "18814        0        0        7        0        0     75.0     47.0  \n",
      "18815        0        0        7        0        0     72.0     38.0  \n",
      "18816        0        0        7        0        0     66.0     40.0  \n",
      "18817        0        0        3        0        0     71.0     43.0  \n",
      "\n",
      "[18818 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "stationWeeklyWeatherDf_resampled = pd.DataFrame()  # Create an empty DataFrame for resampled data\n",
    "\n",
    "for station_name, group in weeklyWeatherDf.groupby('STATION'):\n",
    "    group.set_index('DATE', inplace=True)\n",
    "    group.drop(['STATION'], axis=1, inplace=True)\n",
    "    group_resampled = group.resample('W', label = 'left').sum()\n",
    "\n",
    "    absTMAX = group['TMAX'].resample('W', label = 'left').max()\n",
    "    absTMIN = group['TMIN'].resample('W', label = 'left').min()\n",
    "\n",
    "    group_resampled.insert(0,'STATION', station_name)\n",
    "    group_resampled['absTMAX'] = absTMAX\n",
    "    group_resampled['absTMIN'] = absTMIN\n",
    "\n",
    "    stationWeeklyWeatherDf_resampled = pd.concat([stationWeeklyWeatherDf_resampled, group_resampled])\n",
    "  # Reset the index\n",
    "\n",
    "stationWeeklyWeatherDf_resampled.reset_index(inplace=True)\n",
    "\n",
    "print(stationWeeklyWeatherDf_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DATE      STATION      AWND      Begin        End  AVG PRECIP  \\\n",
      "0     2012-12-30  US1CARV0002  0.000000 2012-12-30 2013-01-05    0.000000   \n",
      "1     2013-01-06  US1CARV0002       NaN 2013-01-06 2013-01-12    0.054286   \n",
      "2     2013-01-13  US1CARV0002       NaN 2013-01-13 2013-01-19    0.000000   \n",
      "3     2013-01-20  US1CARV0002       NaN 2013-01-20 2013-01-26    0.318571   \n",
      "4     2013-01-27  US1CARV0002       NaN 2013-01-27 2013-02-02    0.057143   \n",
      "...          ...          ...       ...        ...        ...         ...   \n",
      "18813 2019-12-01  USW00093138  2.907143 2019-12-01 2019-12-07    0.060000   \n",
      "18814 2019-12-08  USW00093138  4.058571 2019-12-08 2019-12-14    0.000000   \n",
      "18815 2019-12-15  USW00093138  5.081429 2019-12-15 2019-12-21    0.000000   \n",
      "18816 2019-12-22  USW00093138  3.324286 2019-12-22 2019-12-28    0.137143   \n",
      "18817 2019-12-29  USW00093138  2.492857 2019-12-29 2020-01-04    0.000000   \n",
      "\n",
      "       TOTAL PRECIP  AVG SNOW  TOTAL SNOW  AVG TEMP  AVG MAX TEMP  MAX TEMP  \\\n",
      "0              0.00  2.500000        0.00       0.0      0.000000       NaN   \n",
      "1              0.38  0.250000        0.38       NaN           NaN       NaN   \n",
      "2              0.00  0.000000        0.00       NaN           NaN       NaN   \n",
      "3              2.23  0.000000        2.23       NaN           NaN       NaN   \n",
      "4              0.40  0.833333        0.40       NaN           NaN       NaN   \n",
      "...             ...       ...         ...       ...           ...       ...   \n",
      "18813          0.42  0.000000        0.42       NaN     67.142857      71.0   \n",
      "18814          0.00  0.000000        0.00       NaN     72.714286      75.0   \n",
      "18815          0.00  0.000000        0.00       NaN     66.142857      72.0   \n",
      "18816          0.96  0.000000        0.96       NaN     61.000000      66.0   \n",
      "18817          0.00  0.000000        0.00       0.0     28.142857      71.0   \n",
      "\n",
      "       AVG MIN TEMP  MIN TEMP      TAVG2  \n",
      "0          0.000000       NaN   0.000000  \n",
      "1               NaN       NaN        NaN  \n",
      "2               NaN       NaN        NaN  \n",
      "3               NaN       NaN        NaN  \n",
      "4               NaN       NaN        NaN  \n",
      "...             ...       ...        ...  \n",
      "18813     51.714286      47.0  59.428571  \n",
      "18814     49.428571      47.0  61.071429  \n",
      "18815     44.142857      38.0  55.142857  \n",
      "18816     44.000000      40.0  52.500000  \n",
      "18817     19.857143      43.0  24.000000  \n",
      "\n",
      "[18818 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#'STATION', 'AWND', 'AVG PRECIP', 'TOTAL PRECIP', 'AVG SNOW',\n",
    "#'TOTAL SNOW', 'AVG TEMP', 'AVG MAX TEMP', 'MAX TEMP', 'AVG MIN TEMP',\n",
    "#'MIN TEMP', 'TAVG2', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'Begin', 'End'\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['Begin'] = stationWeeklyWeatherDf_resampled['DATE']\n",
    "stationWeeklyWeatherDf_resampled['End'] = stationWeeklyWeatherDf_resampled['DATE']+datetime.timedelta(days=6)\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['AWND'] = stationWeeklyWeatherDf_resampled['AWND']/(7-stationWeeklyWeatherDf_resampled['awndnan'])\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['AVG PRECIP'] = stationWeeklyWeatherDf_resampled['PRCP']/(7-stationWeeklyWeatherDf_resampled['prcpnan'])\n",
    "stationWeeklyWeatherDf_resampled['TOTAL PRECIP'] = stationWeeklyWeatherDf_resampled['PRCP']\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['AVG SNOW'] = stationWeeklyWeatherDf_resampled['SNWD']/(7-stationWeeklyWeatherDf_resampled['snwdnan'])\n",
    "stationWeeklyWeatherDf_resampled['TOTAL SNOW'] = stationWeeklyWeatherDf_resampled['PRCP']\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['AVG TEMP'] = stationWeeklyWeatherDf_resampled['TAVG']/(7-stationWeeklyWeatherDf_resampled['tavgnan'])\n",
    "\n",
    "stationWeeklyWeatherDf_resampled['AVG MAX TEMP'] = stationWeeklyWeatherDf_resampled['TMAX']/(7-stationWeeklyWeatherDf_resampled['tmaxnan'])\n",
    "stationWeeklyWeatherDf_resampled['MAX TEMP'] = stationWeeklyWeatherDf_resampled['absTMAX']\n",
    "stationWeeklyWeatherDf_resampled['AVG MIN TEMP'] = stationWeeklyWeatherDf_resampled['TMIN']/(7-stationWeeklyWeatherDf_resampled['tminnan'])\n",
    "stationWeeklyWeatherDf_resampled['MIN TEMP'] = stationWeeklyWeatherDf_resampled['absTMIN']\n",
    "stationWeeklyWeatherDf_resampled['TAVG2'] = (stationWeeklyWeatherDf_resampled['AVG MAX TEMP']+stationWeeklyWeatherDf_resampled['AVG MIN TEMP'])/2\n",
    "\n",
    "stationWeeklyWeatherDf_resampled.drop(['PRCP', 'SNWD', 'TAVG', 'TMAX', 'TMIN'], axis=1, inplace=True)\n",
    "stationWeeklyWeatherDf_resampled.drop(['awndnan', 'prcpnan', 'snwdnan', 'tavgnan', 'tmaxnan', 'tminnan', 'absTMAX', 'absTMIN'], axis=1, inplace=True)\n",
    "\n",
    "print(stationWeeklyWeatherDf_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fillWithTotalAverageValues():\n",
    "    averageWeeklyWeatherDf = stationWeeklyWeatherDf_resampled.groupby('DATE').mean()\n",
    "    averageWeeklyWeatherDf = averageWeeklyWeatherDf.add_suffix('_y')\n",
    "\n",
    "    columns_to_fill = stationWeeklyWeatherDf_resampled.columns.difference(['DATE', 'STATION', 'Begin', 'End'])\n",
    "\n",
    "    # Merge the station-separated data with the averaged values based on the date\n",
    "    finalWeeklyWeatherDf = stationWeeklyWeatherDf_resampled.merge(averageWeeklyWeatherDf, on='DATE', how='left')\n",
    "\n",
    "    # Fill missing values in the specified columns with the corresponding averaged values\n",
    "    for col in columns_to_fill:\n",
    "        finalWeeklyWeatherDf[col].fillna(finalWeeklyWeatherDf[col+'_y'], inplace=True)\n",
    "        finalWeeklyWeatherDf.drop([col+'_y'], axis=1, inplace=True)\n",
    "\n",
    "    # Drop the extra columns (if needed)\n",
    "\n",
    "    finalWeeklyWeatherDf = finalWeeklyWeatherDf.merge(stationInfoDf, on='STATION', how='left')\n",
    "    finalWeeklyWeatherDf.drop(['NAME', 'stationList'], axis=1, inplace=True)\n",
    "    return finalWeeklyWeatherDf\n",
    "# The resulting DataFrame 'finalWeeklyWeatherDf' will have the station-separated data with missing values filled using the averaged values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to double check\n",
    "\n",
    "def fillWithClosestStationValues():\n",
    "# Select the columns to fill\n",
    "    finalWeeklyWeatherDf = stationWeeklyWeatherDf_resampled.copy()\n",
    "    columns_to_fill = finalWeeklyWeatherDf.columns.difference(['DATE', 'STATION'])\n",
    "    grouped_finalWeeklyWeatherDf = finalWeeklyWeatherDf.groupby('STATION')\n",
    "    # Iterate over the columns and fill missing values with values from the closest station\n",
    "    for station_name, group in grouped_finalWeeklyWeatherDf:\n",
    "        closest_station_arr = stationInfoDf.at[station_name, 'stationList'] #row then column, STATION is index in the info df\n",
    "        \n",
    "        for row_index, row in group.iterrows(): #go through each week of station\n",
    "            #print(row_index)\n",
    "            currentDate = row[0]\n",
    "            for col in columns_to_fill: #fill each column for the week\n",
    "                if pd.isnull(row[col]): #row[col] is value to fill when nan\n",
    "                    for station in closest_station_arr:\n",
    "                        column_to_match = 'DATE'\n",
    "                        value_to_match = currentDate\n",
    "                        column_to_retrieve = col \n",
    "                        new_group = grouped_finalWeeklyWeatherDf.get_group(station)\n",
    "\n",
    "                        filtered_group = new_group[new_group[column_to_match] == value_to_match] #finding where that station has the row for the week\n",
    "\n",
    "                        if filtered_group.empty: #if station does not have that week\n",
    "                            continue\n",
    "\n",
    "                        val = filtered_group[column_to_retrieve].iat[0] #val to fill\n",
    "                        if np.isnan(val): #if the val is empty look at next station's val\n",
    "                            continue\n",
    "\n",
    "                        finalWeeklyWeatherDf.at[row_index, col]=val #set the val and go to next column to fill\n",
    "                        break\n",
    "    finalWeeklyWeatherDf = finalWeeklyWeatherDf.merge(stationInfoDf, on='STATION', how='left')\n",
    "    finalWeeklyWeatherDf.drop(['NAME', 'stationList'], axis=1, inplace=True)\n",
    "    return finalWeeklyWeatherDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DATE      STATION      AWND      Begin        End  AVG PRECIP  \\\n",
      "0     2012-12-30  US1CARV0002  0.000000 2012-12-30 2013-01-05    0.000000   \n",
      "1     2013-01-06  US1CARV0002  0.000000 2013-01-06 2013-01-12    0.054286   \n",
      "2     2013-01-13  US1CARV0002  0.000000 2013-01-13 2013-01-19    0.000000   \n",
      "3     2013-01-20  US1CARV0002  0.000000 2013-01-20 2013-01-26    0.318571   \n",
      "4     2013-01-27  US1CARV0002  0.000000 2013-01-27 2013-02-02    0.057143   \n",
      "...          ...          ...       ...        ...        ...         ...   \n",
      "18813 2019-12-01  USW00093138  2.907143 2019-12-01 2019-12-07    0.060000   \n",
      "18814 2019-12-08  USW00093138  4.058571 2019-12-08 2019-12-14    0.000000   \n",
      "18815 2019-12-15  USW00093138  5.081429 2019-12-15 2019-12-21    0.000000   \n",
      "18816 2019-12-22  USW00093138  3.324286 2019-12-22 2019-12-28    0.137143   \n",
      "18817 2019-12-29  USW00093138  2.492857 2019-12-29 2020-01-04    0.000000   \n",
      "\n",
      "       TOTAL PRECIP  AVG SNOW  TOTAL SNOW   AVG TEMP  AVG MAX TEMP  MAX TEMP  \\\n",
      "0              0.00  2.500000        0.00   0.000000      0.000000      69.0   \n",
      "1              0.38  0.250000        0.38  45.857143     60.714286      76.0   \n",
      "2              0.00  0.000000        0.00  51.285714     71.428571      79.0   \n",
      "3              2.23  0.000000        2.23  57.714286     69.571429      82.0   \n",
      "4              0.40  0.833333        0.40  54.142857     70.142857      78.0   \n",
      "...             ...       ...         ...        ...           ...       ...   \n",
      "18813          0.42  0.000000        0.42   0.000000     67.142857      71.0   \n",
      "18814          0.00  0.000000        0.00   0.000000     72.714286      75.0   \n",
      "18815          0.00  0.000000        0.00   0.000000     66.142857      72.0   \n",
      "18816          0.96  0.000000        0.96   0.000000     61.000000      66.0   \n",
      "18817          0.00  0.000000        0.00   0.000000     28.142857      71.0   \n",
      "\n",
      "       AVG MIN TEMP  MIN TEMP      TAVG2   LATITUDE  LONGITUDE  ELEVATION  \n",
      "0          0.000000      33.0   0.000000  33.763056 -116.73500     1927.9  \n",
      "1         34.428571      29.0  47.571429  33.763056 -116.73500     1927.9  \n",
      "2         37.857143      26.0  54.642857  33.763056 -116.73500     1927.9  \n",
      "3         48.714286      42.0  59.142857  33.763056 -116.73500     1927.9  \n",
      "4         42.857143      33.0  56.500000  33.763056 -116.73500     1927.9  \n",
      "...             ...       ...        ...        ...        ...        ...  \n",
      "18813     51.714286      47.0  59.428571  33.822160 -116.50433      124.7  \n",
      "18814     49.428571      47.0  61.071429  33.822160 -116.50433      124.7  \n",
      "18815     44.142857      38.0  55.142857  33.822160 -116.50433      124.7  \n",
      "18816     44.000000      40.0  52.500000  33.822160 -116.50433      124.7  \n",
      "18817     19.857143      43.0  24.000000  33.822160 -116.50433      124.7  \n",
      "\n",
      "[18818 rows x 18 columns]\n",
      "Stored 'finalWeeklyWeatherDf' (DataFrame)\n",
      "Stored 'stationInfoDf' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "#finalWeeklyWeatherDf = fillWithTotalAverageValues()\n",
    "finalWeeklyWeatherDf = fillWithClosestStationValues()\n",
    "print(finalWeeklyWeatherDf)\n",
    "\n",
    "%store finalWeeklyWeatherDf\n",
    "%store stationInfoDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE            0\n",
      "STATION         0\n",
      "AWND            0\n",
      "Begin           0\n",
      "End             0\n",
      "AVG PRECIP      0\n",
      "TOTAL PRECIP    0\n",
      "AVG SNOW        0\n",
      "TOTAL SNOW      0\n",
      "AVG TEMP        0\n",
      "AVG MAX TEMP    0\n",
      "MAX TEMP        0\n",
      "AVG MIN TEMP    0\n",
      "MIN TEMP        0\n",
      "TAVG2           0\n",
      "LATITUDE        0\n",
      "LONGITUDE       0\n",
      "ELEVATION       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(finalWeeklyWeatherDf.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
